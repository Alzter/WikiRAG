{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0883d8200a4a87aafa6fc01d611133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Load the model using 4-bit quantization (1/2 size)\n",
    "# Source: https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config = quantization_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llama(prompt):\n",
    "    sequences = pipeline(\n",
    "        f'{prompt}\\n',\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        truncation = True,\n",
    "        max_length=400,\n",
    "    )\n",
    "\n",
    "    for seq in sequences:\n",
    "        print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "c:\\Users\\Alex\\anaconda3\\envs\\gpu_tf\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Hello?\n",
      "Hello?\n",
      "Hello?\n",
      "I'm not sure what I'm looking for, but I know I'll know it when I see it.\n",
      "I'm not sure what I'm searching for, but I know I'll know it when I find it.\n",
      "I'm not sure what I'm seeking, but I know I'll know it when I see it.\n",
      "The truth is, I'm not even sure what I'm doing here.\n",
      "I'm just wandering, aimlessly, through the digital halls of the internet.\n",
      "I'm just browsing, aimlessly, through the endless streams of information.\n",
      "I'm just searching, aimlessly, for something, anything, that will spark my interest.\n",
      "And then, suddenly, I stumble upon something.\n",
      "A word, a phrase, a sentence, a paragraph.\n",
      "A spark of interest, a glimmer of curiosity.\n",
      "And I'm hooked.\n",
      "I'm drawn in, like a magnet to metal.\n",
      "I'm consumed, like a fire consumes wood.\n",
      "I'm lost, like a ship without a compass.\n",
      "But I'm not lost, because I've found something.\n",
      "Something that resonates, something that speaks to me.\n",
      "Something that makes me feel, something that makes me think.\n",
      "And I'm not alone, because I've found others who feel the same way.\n",
      "Others who think the same thoughts, who see the same things.\n",
      "And we're connected, like threads in a tapestry.\n",
      "We're linked, like stars in a constellation.\n",
      "We're a community, a tribe, a family.\n",
      "And I'm home, because I've found my place.\n",
      "My place in the world, my place in the universe.\n",
      "My place in the digital halls of the internet.\n",
      "Where I can be myself, where I can be free.\n",
      "Where I can find others who see the world the same way.\n",
      "And where I can share my thoughts, my feelings, my experiences.\n",
      "And where I can connect with others, in a way that's both intimate and anonymous.\n",
      "The internet, a\n"
     ]
    }
   ],
   "source": [
    "query_llama(\"Hello?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
