{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\ProjectCSurvival\\rag\\retrieval.py:258: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(summary_files) == len(summary_embeddings), \"Summary text files should directly map to summary embedding files.\")\n",
      "c:\\Users\\Alex\\ProjectCSurvival\\rag\\retrieval.py:303: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(embedding_files) == len(embedding_texts), \"Embedding raw text files should directly map to embedding data files.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files in knowledge...\n",
      "Loading knowledge base from path '..\\context\\knowledge_base'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading knowledge base: 100%|██████████| 12871/12871 [04:25<00:00, 48.40article/s, Zionist po...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transformer model and tokenizer from transformers library: avsolatorio/NoInstruct-small-Embedding-v0\n",
      "Please wait...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retrieval import Retrieval\n",
    "retrieval = Retrieval(\"..\\context\\knowledge_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krazy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "c:\\Users\\krazy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('A, or a, is the first letter and the first vowel letter of the Latin alphabet, used in the modern English alphabet, and others worldwide. Its name in English is \"a\" (pronounced ), plural \"aes\".',\n",
       " 'A')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval.get_context(\"What is the first principle of animation?\", num_contexts=1, use_sparse_retrieval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A, or a, is the first letter and the first vowel letter of the Latin alphabet, used in the modern English alphabet, and others worldwide. Its name in English is \"a\" (pronounced ), plural \"aes\".',\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval.get_context(\"What is the first principle of animation?\", num_contexts=1, use_sparse_retrieval=False, exhaustive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding user query for dense retrieval:\n",
      "Finding best article to use as context with hnsw retrieval:\n",
      "SCORES: [ 0  7  2  1  6  4  8 10 13  5]\n",
      "Scores: [ 0  7  2  1  6  4  8 10 13  5]\n",
      "Best indices: [8]\n",
      "Candidate title: A. A. Milne\n",
      "Using Wikipedia article: A. A. Milne for context\n",
      "Found 32 chunks for within context.\n",
      "Finding best article chunks to use as context with dense retrieval:\n",
      "Scores: [tensor(0.6394), tensor(0.6576), tensor(0.6308), tensor(0.6450), tensor(0.6288), tensor(0.6081), tensor(0.6094), tensor(0.5989), tensor(0.6023), tensor(0.6005), tensor(0.6487), tensor(0.6338), tensor(0.6335), tensor(0.6554), tensor(0.6193), tensor(0.6604), tensor(0.6305), tensor(0.6224), tensor(0.6185), tensor(0.6155), tensor(0.6615), tensor(0.6147), tensor(0.5941), tensor(0.5951), tensor(0.6373), tensor(0.6143), tensor(0.5739), tensor(0.5753), tensor(0.6691), tensor(0.6388), tensor(0.6331), tensor(0.6420)]\n",
      "Best indices: [28]\n",
      "Context successfully retrieved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('After graduating from Cambridge University in 1903, A. A. Milne contributed humorous verse and whimsical essays to \"Punch\", joining the staff in 1906 and becoming an assistant editor.',\n",
       " 'A. A. Milne')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval.get_context(\"What is the first principle of animation?\", num_contexts=1, hnsw = True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding user query for dense retrieval:\n",
      "Finding best article to use as context with sparse retrieval:\n",
      "Using Wikipedia article: A for context\n",
      "Found 16 chunks for within context.\n",
      "Finding best article chunks to use as context with dense retrieval:\n",
      "Context successfully retrieved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('A, or a, is the first letter and the first vowel letter of the Latin alphabet, used in the modern English alphabet, and others worldwide. Its name in English is \"a\" (pronounced ), plural \"aes\".',\n",
       " 'A')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval.get_context(\"What is the first principle of animation?\", num_contexts=1, use_sparse_retrieval=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding user query for dense retrieval:\n",
      "Finding best article to use as context with dense retrieval:\n",
      "Using Wikipedia article: A for context\n",
      "Found 16 chunks for within context.\n",
      "Finding best article chunks to use as context with dense retrieval:\n",
      "Context successfully retrieved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('A, or a, is the first letter and the first vowel letter of the Latin alphabet, used in the modern English alphabet, and others worldwide. Its name in English is \"a\" (pronounced ), plural \"aes\".',\n",
       " 'A')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval.get_context(\"What is the first principle of animation?\", num_contexts=1,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
